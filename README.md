# LLaMA2_Fine-Tuning_with_LoRA-
LLaMA2 Fine-Tuning with LoRA is a PEFT method to efficiently adapt the large LLaMA2 model. By training small adapter matrices instead of all parameters, it drastically reduces memory and compute costs.
